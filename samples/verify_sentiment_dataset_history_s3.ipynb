{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Dataset Verification Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This sample verifies a tamper-proof dataset history.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "import random\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from vbase import (\n",
    "    VBaseClient,\n",
    "    VBaseDataset,\n",
    ")\n",
    "from aws_utils import (\n",
    "    create_s3_client_from_env,\n",
    "    init_vbase_dataset_from_s3_objects,\n",
    ")\n",
    "\n",
    "#  Install vBase requirements.\n",
    "!pip install git+https://github.com/validityBase/vbase-py.git\n",
    "!wget --no-clobber https://raw.githubusercontent.com/validityBase/vbase-py-samples-collab/main/samples/collab_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset owner address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_OWNER = \"0xA401F59d7190E4448Eb60691E3bc78f1Ef03e88C\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"sentiment_dataset_20240620103503\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"vbase-test\"\n",
    "FOLDER_NAME = \"samples/sentiment_dataset_history/\"\n",
    "DATASET_FOLDER_NAME = FOLDER_NAME + DATASET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the information necessary to call vBase APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the environment using Google Collab secrets, if possible.\n",
    "try_add_user_secrets_to_env([\n",
    "    \"VBASE_API_KEY\",\n",
    "    \"VBASE_FORWARDER_URL\",\n",
    "    \"VBASE_COMMITMENT_SERVICE_PRIVATE_KEY\",\n",
    "    \"AWS_ACCESS_KEY_ID\",\n",
    "    \"AWS_SECRET_ACCESS_KEY\"\n",
    "])\n",
    "assert load_dotenv(verbose=True, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to AWS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_client = create_s3_client_from_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to vBase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbc = VBaseClient.create_instance_from_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = VBaseDataset(\n",
    "    vbc,\n",
    "    init_dict={\n",
    "        \"name\": DATASET_NAME,\n",
    "        \"owner\": DATASET_OWNER,\n",
    "        \"record_type_name\": \"VBaseJsonObject\",\n",
    "        \"records\": [],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if \"ipykernel\" not in sys.modules and \"IPython\" in sys.modules:\n",
    "    # Configure plot backend if running in interactive mode.\n",
    "    # The following line creates overactive warning.\n",
    "    # We want the import within the clause.\n",
    "    # pylint: disable=ungrouped-imports\n",
    "    import matplotlib\n",
    "\n",
    "    # Set plot backend to WebAgg.\n",
    "    # This backend provides interactive web charts.\n",
    "    matplotlib.use(\"WebAgg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the Dataset History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = init_vbase_dataset_from_s3_objects(\n",
    "    ds, boto_client, BUCKET_NAME, DATASET_FOLDER_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restore timestamps using the blockchain stamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ds.try_restore_timestamps_from_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ds.verify_commitments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and display the verified records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "l_receipts = ds.get_commitment_receipts()\n",
    "html = \"<table>\"\n",
    "html += \"<tr><th>num</th><th>record</th><th>record_hash</th><th>tx</th></tr>\"\n",
    "# Populate the table with data.\n",
    "for i, record in enumerate(ds.records):\n",
    "    html += (\n",
    "        f\"<tr><td>{i}</td><td>{record.data}</td><td>{record.cid}</td>\"\n",
    "        f\"<td>{l_receipts[i]['transactionHash']}</td></tr>\"\n",
    "    )\n",
    "html += \"</table>\"\n",
    "# Check if the script is running in an interactive mode or a Jupyter notebook.\n",
    "if \"ipykernel\" not in sys.modules and \"IPython\" in sys.modules:\n",
    "    pprint.pprint(html)\n",
    "else:\n",
    "    # Load support for HTML display, if necessary.\n",
    "    from IPython.display import display, HTML\n",
    "\n",
    "    # Display the HTML table in the Jupyter notebook.\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataset data to a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = ds.get_pd_data_frame()\n",
    "print(\"Dataset DataFrame:\\n\", df_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data to a signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_signal = (df_dataset - 50) / 50\n",
    "print(\"Signal DataFrame:\\n\", df_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot validated signal return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "df_asset_returns = pd.DataFrame(\n",
    "    (np.random.random(size=df_signal.shape) * 2 - 1) / 20,\n",
    "    index=df_signal.index,\n",
    "    columns=df_signal.columns,\n",
    ")\n",
    "df_signal_returns = (df_signal.shift(1) * df_asset_returns).sum(axis=1)\n",
    "print(\"\\nReturns DataFrame:\\n\", df_signal_returns)\n",
    "(1 + df_signal_returns).cumprod().fillna(1).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Process<br>\n",
    "* We used only a link to the dataset history, name and owner.<br>\n",
    "* We validated data integrity and timestamps using public blockchain records.<br>\n",
    "* We converted the historical data to a Pandas DataFrame for easy analysis.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Key Implications<br>\n",
    "* The track record and all analytics can be independently calculated and verified forever.<br>\n",
    "* Data can be validated with a single line.<br>\n",
    "* vBase integrates smoothly with existing data science libraries and workflows.<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
